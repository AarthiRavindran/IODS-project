##**RStudio Exercise 1: Tasks and Instructions**
Third week class is about logistic regression.  

*Logistic REgression:*  
This is an statistical model that uses a logistic function to model a binary dependent variable. In logistic regression (or logit regression) is estimating the parameters in the form of binary (0 and 1) as we seen in previous exercise the use of linear regression is to estimate the parameters that in the continuous form (-infinity to +infinity).  

*Data wrangling (max 5 points)*
1. Take the data file student-mat.csv and student-por.csv from given link.  
2. Creat new rscript in 'create_alc.R' and save in data file
3. Read both student-mat.csv and student-por.csv files and explore the structure and dimensions of the data - (1 point- Done)  
4. Join the two data sets using the variables "school", "sex", "age", "address", "famsize", "Pstatus", "Medu", "Fedu", "Mjob", "Fjob", "reason", "nursery","internet" as (student) identifiers. Keep only the students present in both data sets. Explore the structure and dimensions of the joined data. (1 point - Done)  
5. Either a) copy the solution from the DataCamp exercise The if-else structure to combine the 'duplicated' answers in the joined data, or b) write your own solution to achieve this task. (1 point - Done)
6. Take the average of the answers related to weekday and weekend alcohol consumption to create a new column 'alc_use' to the joined data. Then use 'alc_use' to create a new logical column 'high_use' which is TRUE for students for which 'alc_use' is greater than 2 (and FALSE otherwise). (1 point - done)  
7. Glimpse at the joined and modified data to make sure everything is in order. The joined data should now have 382 observations of 35 variables. Save the joined and modified data set to the 'data' folder, using for example write.csv() or write.table() functions. (1 point - done)  

#Aarthi Ravindran, 13th September 2019

#Data Wrangling - 5 points
#1. Take the data file student-mat.csv and student-por.csv from given link.  
#2. Creat new rscript in 'create_alc.R' and save in data file
#3. Read both student-mat.csv and student-por.csv files and explore the structure and dimensions of the data.  

```{r readfiles}
# Reading the files
student_mat <- read.csv("C:/Users/Aarthi/Documents/IODS-project/data/student-mat.csv", sep = ";", header = TRUE)
student_por <- read.csv("C:/Users/Aarthi/Documents/IODS-project/data/student-por.csv", sep = ";", header = TRUE)
```

```{r explorefiles}
# Explore the files
dim(student_mat)
dim(student_por)
str(student_mat)
str(student_por)
```

```{r joindata}
#Join the data
library(dplyr)
join_by <- c("school", "sex", "age", "address", "famsize", "Pstatus", "Medu", "Fedu", "Mjob", "Fjob", "reason", "nursery","internet")
student_mat_por_joined <- inner_join(student_mat, student_por, by=join_by)
dim(student_mat_por_joined)
str(student_mat_por_joined)
glimpse(student_mat_por_joined)

# result intepretation : when i eplore joined data, it seems the duplicates are joined as x and y cordinates, so we have to remove the duplicates
```

```{r duplicate_removal}
#To combine the duplicates
# create a new data frame with only the joined columns
alc <- select(student_mat_por_joined, one_of(join_by))

# columns that were not used for joining the data
notjoined_columns <- colnames(student_mat)[!colnames(student_mat) %in% join_by]

# print out the columns not used for joining
notjoined_columns

# for every column name not used for joining...
for(column_name in notjoined_columns) {
  # select two columns from 'math_por' with the same original name
  two_columns <- select(student_mat_por_joined, starts_with(column_name))
  # select the first column vector of those two columns
  first_column <- select(two_columns, 1)[[1]]
  
  # if that first column  vector is numeric...
  if(is.numeric(first_column)) {
    # take a rounded average of each row of the two columns and
    # add the resulting vector to the alc data frame
    alc[column_name] <- round(rowMeans(two_columns))
  } else { # else if it's not numeric...
    # add the first column vector to the alc data frame
    alc[column_name] <- first_column
  }
}

# glimpse at the new combined data
glimpse(alc)
```

```{r creation_of_new_col}
#Take average of weekend and weekday alcohol consumption by creating new column in the data
alc <- mutate(alc, alc_use = (Dalc + Walc) / 2)
#Create new column by highuse in which the students who have value more than 2 is TRUE
alc <- mutate(alc, high_use = "alc_use" > 2)
glimpse(alc)
```

write.csv(alc, "C:/Users/Aarthi/Documents/IODS-project/data/new_data.csv")
write.table(alc, "C:/Users/Aarthi/Documents/IODS-project/data/new_data.txt")

*Analysis (max 15 points)*
1. Create 'chapter3.Rmd' and include it in 'index.Rmd' to perform analysis in chapter3.Rmd file. (Done)  
2. Read the joined and print the variables in the data and describe it (0-1 point). (Done)  
3. 
The purpose of your analysis is to study the relationships between high/low alcohol consumption and some of the other variables in the data. To do this, choose 4 interesting variables in the data and for each of them, present your personal hypothesis about their relationships with alcohol consumption. (0-1 point)

Numerically and graphically explore the distributions of your chosen variables and their relationships with alcohol consumption (use for example cross-tabulations, bar plots and box plots). Comment on your findings and compare the results of your exploration to your previously stated hypotheses. (0-5 points)

Use logistic regression to statistically explore the relationship between your chosen variables and the binary high/low alcohol consumption variable as the target variable. Present and interpret a summary of the fitted model. Present and interpret the coefficients of the model as odds ratios and provide confidence intervals for them. Interpret the results and compare them to your previously stated hypothesis. Hint: If your model includes factor variables see for example the first answer of this stackexchange thread on how R treats and how you should interpret these variables in the model output (or use some other resource to study this). (0-5 points)

Using the variables which, according to your logistic regression model, had a statistical relationship with high/low alcohol consumption, explore the predictive power of you model. Provide a 2x2 cross tabulation of predictions versus the actual values and optionally display a graphic visualizing both the actual values and the predictions. Compute the total proportion of inaccurately classified individuals (= the training error) and comment on all the results. Compare the performance of the model with performance achieved by some simple guessing strategy. (0-3 points)

Bonus: Perform 10-fold cross-validation on your model. Does your model have better test set performance (smaller prediction error using 10-fold cross-validation) compared to the model introduced in DataCamp (which had about 0.26 error). Could you find such a model? (0-2 points to compensate any loss of points from the above exercises)

Super-Bonus: Perform cross-validation to compare the performance of different logistic regression models (= different sets of predictors). Start with a very high number of predictors and explore the changes in the training and testing errors as you move to models with less predictors. Draw a graph displaying the trends of both training and testing errors by the number of predictors in the model. (0-4 points to compensate any loss of points from the above exercises)
*start of analysis*
About data:  
This data is based on student alcohol consumption. The student who are present in two different data are taken and combined. The joined data set has 382 students and has description about their school name, sex, age of the student, their address, family size, parents status, mothers education, fathers education, mothers job, fathers job, activities, alcohol consumption per day and in weekend, their health, average of alcohol usage and column saying whether they are drinking high or not.  
```{r print_variables}
alc <- read.table("C:/Users/Aarthi/Documents/IODS-project/data/new_data.txt", sep = " ")
colnames(alc)
```
The variables that might be associated or affected with the alcohol consumption from my point of view is sex, health, absences, failures and activities. 
```{r explore_data}
#install.packages("ggplot2")
#install.packages("tidyverse")
library(tidyverse)
library(ggplot2)
gather(alc) %>% glimpse
gather(alc) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar()
alc %>% group_by(sex, high_use) %>% summarise(count = n(), mean_grade = mean(G3))
alc %>% group_by(activities, high_use) %>% summarise(count = n(), mean_grade = mean(G3))

```

 